{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-03 22:51:09.724357: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-03 22:51:10.251332: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-04-03 22:51:15.497810: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import copy\n",
    "import util_cochlea\n",
    "# import concurrent.futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looad cochlea config parameters\n",
    "\n",
    "# dir_model = 'models/tensorflow2/arch01'\n",
    "# fn_config = os.path.join(dir_model, 'config.json')\n",
    "# with open(fn_config, 'r') as f:\n",
    "#     CONFIG = json.load(f)\n",
    "\n",
    "# # kwargs_cochlea = CONFIG['kwargs_cochlea']\n",
    "\n",
    "#### kwargs_cochlea from models/tensorflow2/arch01\n",
    "\n",
    "# kwargs_cochlea =  {'config_filterbank': {'max_hi': 20000.0,\n",
    "# 'min_lo': 30.0,\n",
    "# 'mode': 'half_cosine_filterbank',\n",
    "# 'num_cf': 39},\n",
    "# 'config_subband_processing': {'power_compression': 0.3, 'rectify': True},\n",
    "# 'kwargs_fir_lowpass_filter_input': {},\n",
    "# 'kwargs_fir_lowpass_filter_output': {'cutoff': 4000,\n",
    "# 'numtaps': 4097,\n",
    "# 'window': ['kaiser', 5.0]},\n",
    "# 'sr_cochlea': 48000,\n",
    "# 'sr_input': 48000,\n",
    "# 'sr_output': 8000}\n",
    "\n",
    "# dur = 2 # 2 seconds\n",
    "# sr = 48000\n",
    "# y = audio_data[:48000].reshape(1, sr, dur)\n",
    "# # Cochlear model for ear index 0\n",
    "# y0, _ = util_cochlea.cochlea(y[..., 0], **copy.deepcopy(kwargs_cochlea))\n",
    "# # Cochlear model for ear index 1\n",
    "# y1, _ = util_cochlea.cochlea(y[..., 1], **copy.deepcopy(kwargs_cochlea))\n",
    "\n",
    "# y_out = np.concatenate([y0.numpy(), y1.numpy()], axis=0)\n",
    "# y_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to process the audio based on above steps, taking input as audio_data and output as y_out\n",
    "\n",
    "def cochlea_processing(audio_path):\n",
    "\n",
    "    dur = 2 # 2 seconds\n",
    "    sr = 48000\n",
    "\n",
    "    audio_data = np.load(os.path.join(audio_path), allow_pickle=True)\n",
    "    print(f\"File: {audio_path}, shape: {audio_data.shape} \\n\\n\")\n",
    "    y = audio_data[:48000].reshape(1, sr, dur)\n",
    "\n",
    "\n",
    "    kwargs_cochlea =  {'config_filterbank': {'max_hi': 20000.0,\n",
    "   'min_lo': 30.0,\n",
    "   'mode': 'half_cosine_filterbank',\n",
    "   'num_cf': 39},\n",
    "  'config_subband_processing': {'power_compression': 0.3, 'rectify': True},\n",
    "  'kwargs_fir_lowpass_filter_input': {},\n",
    "  'kwargs_fir_lowpass_filter_output': {'cutoff': 4000,\n",
    "   'numtaps': 4097,\n",
    "   'window': ['kaiser', 5.0]},\n",
    "  'sr_cochlea': 48000,\n",
    "  'sr_input': 48000,\n",
    "  'sr_output': 8000}\n",
    "    \n",
    "\n",
    "    # Cochlear model for ear index 0\n",
    "    y0, _ = util_cochlea.cochlea(y[..., 0], **copy.deepcopy(kwargs_cochlea))\n",
    "    # Cochlear model for ear index 1\n",
    "    y1, _ = util_cochlea.cochlea(y[..., 1], **copy.deepcopy(kwargs_cochlea))\n",
    "\n",
    "    y_out = np.concatenate([y0.numpy(), y1.numpy()], axis=0)\n",
    "    return y_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_path = '/mnt/lustre/work/macke/mwe234/datasets/simulated/500_spatial_360_7'\n",
    "output_dir = '/mnt/lustre/work/macke/mwe234/datasets/simulated/cochlea_500_spatial_360_7'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "audio_files = [f for f in os.listdir(audio_path) if f.endswith('.npy')]\n",
    "\n",
    "def process_audio(file):\n",
    "    audio = os.path.join(audio_path, file)\n",
    "    y_out = cochlea_processing(audio)\n",
    "    \n",
    "    np.save(os.path.join(output_dir, file), y_out)\n",
    "\n",
    "# with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "#     executor.map(process_audio, audio_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 39, 8000)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load npy /mnt/lustre/work/macke/mwe234/datasets/simulated/500_spatial_360_7/sound_178099-9-0-0_azim160_elev20.npy\n",
    "import numpy as np\n",
    "y_out = np.load('/mnt/lustre/work/macke/mwe234/datasets/simulated/cochlea_500_spatial_360_7/sound_178099-9-0-0_azim160_elev20.npy')\n",
    "y_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[cochlea] converting audio to subbands using half_cosine_filterbank\n",
      "[cochlea] half-wave rectified subbands\n",
      "[tf_fir_resample] interpreted `tensor_input.shape` as [batch, freq=39, time=48000]\n",
      "[tf_fir_resample] `kwargs_fir_lowpass_filter`: {'cutoff': 4000, 'numtaps': 4097, 'window': ['kaiser', 5.0]}\n",
      "[fir_lowpass_filter] sr_filt = 48000 Hz\n",
      "[fir_lowpass_filter] numtaps = 4097 samples\n",
      "[fir_lowpass_filter] fir_dur = 0.08533333333333333 seconds\n",
      "[fir_lowpass_filter] cutoff = 4000 Hz\n",
      "[fir_lowpass_filter] window = ('kaiser', 5.0)\n",
      "[cochlea] resampled subbands from 48000 Hz to 8000 Hz with filter: {'cutoff': 4000, 'numtaps': 4097, 'window': ['kaiser', 5.0]}\n",
      "[cochlea] half-wave rectified resampled subbands\n",
      "[cochlea] applied 0.3 power compression to subbands\n",
      "[cochlea] converting audio to subbands using half_cosine_filterbank\n",
      "[cochlea] half-wave rectified subbands\n",
      "[tf_fir_resample] interpreted `tensor_input.shape` as [batch, freq=39, time=48000]\n",
      "[tf_fir_resample] `kwargs_fir_lowpass_filter`: {'cutoff': 4000, 'numtaps': 4097, 'window': ['kaiser', 5.0]}\n",
      "[fir_lowpass_filter] sr_filt = 48000 Hz\n",
      "[fir_lowpass_filter] numtaps = 4097 samples\n",
      "[fir_lowpass_filter] fir_dur = 0.08533333333333333 seconds\n",
      "[fir_lowpass_filter] cutoff = 4000 Hz\n",
      "[fir_lowpass_filter] window = ('kaiser', 5.0)\n",
      "[cochlea] resampled subbands from 48000 Hz to 8000 Hz with filter: {'cutoff': 4000, 'numtaps': 4097, 'window': ['kaiser', 5.0]}\n",
      "[cochlea] half-wave rectified resampled subbands\n",
      "[cochlea] applied 0.3 power compression to subbands\n"
     ]
    }
   ],
   "source": [
    "# file = 'sound_178099-9-0-0_azim160_elev20.npy'\n",
    "file = audio_files[0]\n",
    "process_audio(file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BinauralLocalizationCNN_tf2_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
